\documentclass[11pt,a4paper,oldfontcommands]{memoir}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{microtype}
\usepackage[dvips]{graphicx}
\usepackage{xcolor}
\usepackage{todonotes}
\usepackage{times}
\usepackage{amsmath}



\usepackage{listings}

\lstset{
  language = C,
  basicstyle=\small,    % the size of the fonts that are used for the code
  stepnumber=1,                           % the step between two line-numbers. If it is 1 each line will be numbered
  numbersep=10pt,                         % how far the line-numbers are from the code
  tabsize=2,                              % tab size in blank spaces
  extendedchars=true,                     %
  breaklines=true,                        % sets automatic line breaking
  captionpos=b,                           % sets the caption-position to top
  mathescape=true,
  stringstyle=\color{white}\ttfamily,
  showspaces=false,           
  showtabs=false,             
  xleftmargin=17pt,
  framexleftmargin=17pt,
  framexrightmargin=17pt,
  framexbottommargin=5pt,
  framextopmargin=5pt,
  showstringspaces=false     
 }

\newcommand\typestyle{\rmfamily\mdseries\upshape}
\newcommand\addtypes[1]{%
  \lstset{morekeywords=[3]{#1}}}

\usepackage[
breaklinks=true,colorlinks=true,
%linkcolor=blue,urlcolor=blue,citecolor=blue,% PDF VIEW
linkcolor=black,urlcolor=black,citecolor=black,% PRINT
bookmarks=true,bookmarksopenlevel=2]{hyperref}

\usepackage{geometry}
% PDF VIEW
% \geometry{total={210mm,297mm},
% left=25mm,right=25mm,%
% bindingoffset=0mm, top=25mm,bottom=25mm}
% PRINT
\geometry{total={210mm,297mm},
left=20mm,right=20mm,
bindingoffset=10mm, top=25mm,bottom=25mm}

\usepackage{bytefield}
\usepackage{msc}

\OnehalfSpacing
%\linespread{1.3}

%%% CHAPTER'S STYLE
\chapterstyle{bianchi}
%\chapterstyle{ger}
%\chapterstyle{madsen}
%\chapterstyle{ell}
%%% STYLE OF SECTIONS, SUBSECTIONS, AND SUBSUBSECTIONS
\setsecheadstyle{\Large\bfseries\sffamily\raggedright}
\setsubsecheadstyle{\large\bfseries\sffamily\raggedright}
\setsubsubsecheadstyle{\bfseries\sffamily\raggedright}


%%% STYLE OF PAGES NUMBERING
%\pagestyle{companion}\nouppercaseheads 
%\pagestyle{headings}
%\pagestyle{Ruled}
\pagestyle{plain}
\makepagestyle{plain}
\makeevenfoot{plain}{\thepage}{}{}
\makeoddfoot{plain}{}{}{\thepage}
\makeevenhead{plain}{}{}{}
\makeoddhead{plain}{}{}{}


\maxsecnumdepth{subsection} % chapters, sections, and subsections are numbered
\maxtocdepth{subsection} % chapters, sections, and subsections are in the Table of Contents


%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%

\begin{document}

%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%
%   TITLEPAGE
%
%   due to variety of titlepage schemes it is probably better to make titlepage manually
%
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%
\thispagestyle{empty}

{%%%
\sffamily
\centering
\Large

~\vspace{\fill}

EPL-2014 384\\
{\huge 
To be defined
}

\vspace{2.5cm}

{\LARGE
Quentin Devos \\
Loïc Fortemps de Loneux
}

\vspace{3.5cm}

A thesis submitted in partial fulfillment for the\\
Master in Computer Science Engineering\\[1em]
in the\\[1em]
Louvain School of Engineering\\
Université Catholique de Louvain

\vspace{3.5cm}

Supervisors: \\
            Prof. Olivier Bonaventure\\
             Prof. Olivier Pereira

\vspace{\fill}

June 2015

%%%
}%%%

\cleardoublepage
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%

\tableofcontents*

\clearpage

%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%



\chapter{Protocol Design}

In this chapter, we will explore the different additions and modifications made to DTLS to support the Multi Path capability. These changes are categorized in three groups:
\begin{itemize}
\item Advertising the extension and the interfaces
\item Establishing secure subflows without introducing attacks vectors
\item Gathering and exchanging statistics data about the health of each flows, regardless of the others. 
\end{itemize}


\section{Multi-Path advertisement}

Our main purpose is to establish this protocol as an extension of DTLS. In this way, we can reuse as much as possible the principles established by Rescorla and Modadugu in \cite{modadugu2004design}. This also explains why we tried not to change the existing DTLS frames and instead to add new frames for new usages.

\subsection{Extension discovery}

The first step, and the first requirement, was to remain compatible with the standard DTLS client and server. To do that, the MPDTLS extension discovery is made through a new entry in the extensions list of the \verb!ClientHello! and \verb!ServerHello! messages. If a non-MPDTLS capable server receives a \verb!ClientHello!, it will ignore the option  as it is specified in the TLS 1.2 specifications (\verb!RFC5246!). This option is carried as any other TLS extension.
\todo[inline]{Expliquer en détail notre extension, diff \% TLS extensions qui ne concernent que les sig\_algo normalement (cf Section A.4.1 de RFC5246}
%The format of this extension is depicted in the figure \ref{fig:extension}.

%\todo[inline]{new \{Client,Server\}Hello}

After the exchange of the \verb!HelloVerifyRequest! and \verb!ClientHello! with Cookie, the server will send back a \verb!ServerHello! containing the same extension if it wants to support MPDTLS features. Besides this MPDTLS extension discovery, the handshake is exactly the one from DTLS, keeping the handshake as light as possible.

\subsection{Interfaces advertising}

Once the handshake is finished and the initial flow is established, the two hosts can advertise new interfaces available for other sub-flows. This advertising is done within the \verb!ChangeInterfaceMessage! (CIM), a packet carrying multiple addresses. The address of each available interface is included under the form presented in figure \ref{fig:cimFormat}. We use 16 bytes for the address to be IPv6 compliant. IPv4 addresses can be translated to/from IPv6 format following \verb!RFC6052! .  

\begin{figure}[!h]
\centering
\begin{bytefield}[bitwidth=\linewidth/20]{18}
\bitbox{16}{Address} & \bitbox{2}{Port}\\
\bitbox[]{16}{16 bytes} & \bitbox[]{2}{2 bytes}
\end{bytefield}
\caption{Change Interface Message : address format}
\label{fig:cimFormat}
\end{figure}

The \verb!CIM! contains all the addresses the host want to share. We decided to always transmit all the addresses to provide redundancy. Also, to be sure that we does not loose potential bandwidth, the \verb!CIM!s are retransmitted in case of loss and so are acknowledged. To avoid wasting resources, we use the acknowledgement to transmit the list of addresses of the receiving host. This way, we are sure that each host knows the exact configuration of the other at any time (once the first host received the acknowledgement). An example of the \verb!CIM! exchange is shown in the Figure \ref{fig:CIMexchange}.

\begin{figure}[!h]
\centering
\begin{msc}[r]{MultiPath-DTLS Addresses announcement}

\setlength{\instfootheight}{0em}
\setlength{\instheadheight}{0em}
\setlength{\instdist}{0.7\linewidth}
\setlength{\levelheight}{3em}

\declinst{client}{Client}{}
\declinst{server}{Server}{}

\lost[r]{ChangeInterfaceMessage[2, client1, client2, reply=1]}[t]{}{client}[7]
\nextlevel
\mess{ChangeInterfaceMessage[2, client1, client2, client3, reply=1]}[t]{client}[0]{server}[1]
\nextlevel
\mess{ChangeInterfaceMessage[1, server1, [reply=0]]}[b]{server}[1]{client}[1]
\nextlevel
\nextlevel

\end{msc}
\caption{Example of Change Interface Message use}
\label{fig:CIMexchange}
\end{figure}

A reply bit is needed and placed into the header of \verb!CIM! to differentiate a new message from an acknowledgement to a previous one.

\section{Secure sub-flows establishment}

In the first design of our protocol, we didn't use any handshake to attach new subflows to the global connection. We realized this could present a potential weak point for a DoS (Denial of Service) attack. Indeed if an attacker could guess IP addresses of the server, he can send garbage under the form of traditional DTLS packets. This could be computation costly since it forces the server to establish the packet authenticity and involves cryptographic operations. Moreover, the handshake initiates a first contact with a new interface and make sure we can communicate with it.

\subsection{Light handshake\todo{Keep or trash ?}}


The objective of this new handshake is to authenticate the host and be able to identify it as being part of the primary connection. We have explored multiple choices of design keeping in mind the following requirements :

\begin{itemize}
\item It must be as secure as a standard DTLS communication
\item The server authenticates the client and inversely
\item We must avoid to introduce another DoS vulnerability
\item Every message can be lost or reordered
\end{itemize}

Since both hosts must authenticate each other, we need at least 3 messages. A last one may be needed to acknowledge the last packet to let the client know he can begin to send packets.

\todo[inline]{Do a nice scheme of our handshake}



\section{Feedback on sub-flow}

Last but not least, each packet must be sent on only one flow. Thus, one need to dispatch the packets over the sub-flows, and this is the role of the scheduler. But, to be able to do efficiently its work, the scheduler must be aware of the sub-flows health. To implement this new feature, we propose to add to DTLS a feedback mechanism, gathering various information such as the Forward delay, the drop rate of the link or the global reorder rate. Crossing the information we receive from different sub-flows will allow the scheduler to dispatch packets efficiently.

\subsection{Forward delay estimation}
The transmission delay is an important measure when we want to balance a load over multiple flows. But, in the first time, we used the RTT to measure this delay, estimating the one-way delay to the half of the RTT. However, as a majority of the links over the Internet are asymmetric, it sometimes leads to major differences between the real one-way delay and our estimation. We thus needed to reconsider the way to compute the delay.

The most intuitive way to compute the time taken to realize a task is to compare the time before its beginning and after its completion, which makes no sense when it comes over the network. As the task begins on one host and finishes on the other, we are subject to the clock synchronisation.

However, \cite{song2009estimator} propose a practical solution that suits our needs. The idea is simple: we don't need to know the exact One-way delay of a subflow, we just need to be able to compare the delays between the different sub-flows. Thus, we can compute the transmission delay of a flow as the difference between the send time and the receive time, with a $\Delta T$ being the clock desynchronization between the two hosts. As the two end-points of each sub-flows are the same, this $\Delta T$ is assumed to be constant over all the sub-flows.

Once we know how to estimates the forward delay of each subflow, or at least how to rank them on this criteria, we can easily create a mechanism to compute this estimation, it is illustrated in the Figure \ref{fig:forwardDelayComputation}. To avoid overhead on each DTLS AppData packets, we took the decision to use new dedicated packets to compute the forward delay. Each host will periodically send probe packet containing the current timestamp. When the other host receives it, it can compute the transmission delay modulo $\Delta T$. For the sake of simplicity, only the average of the delay computed will be transmitted in the \verb!feedback! report, as presented in Section \ref{sec:feedbackReport}. The $\Delta T$ is considered constant over time because the clocks are increasing in the same way on all the hosts. As $\Delta T$ is constant, it does not introduce bias in the calculation of the transmission delay average.

\begin{figure}[!h]
\begin{minipage}[c]{.55\linewidth}
\begin{msc}[r]{Forward Delay estimation}

\setlength{\instfootheight}{0em}
\setlength{\instheadheight}{0em}
\setlength{\instdist}{0.25\linewidth}
\setlength{\levelheight}{3em}

\declinst{c1}{Client$_1$}{}
\declinst{s}{Server}{}
\declinst{c2}{Client$_2$}{}

\mess{Probe($T_1$)}[t]{s}[0]{c1}[1]
\nextlevel
\mess{Probe($T_2$)}[t]{s}[0]{c2}[2]
\mscmark{$T_2'$}{c1}
\nextlevel
\mess{Probe($T_3$)}[t]{s}[0]{c1}[1]
\mess{Probe($T_3$)}[b]{s}[1]{c2}[2]
\nextlevel
\mscmark{$T_4'$}{c1}
\mscmark[tr]{$T_4'$}{c2}
\nextlevel
\mscmark[tr]{$T_5'$}{c2}
\nextlevel
\end{msc}
\caption{Forward Delay estimation mechanism}
\label{fig:forwardDelayComputation}
\end{minipage}
\begin{minipage}[c]{.44\linewidth}
To compute the forward delay, we propose to proceed as follow:\\

The host (\textit{Server} in the Figure \ref{fig:forwardDelayComputation}) sends periodically \verb!Probe! packets containing its current timestamp ($T_x$).\\

Once received by the other host (Client$_{\{1,2\}}$), the latter can compute the transmission delay of this particular packet,
$$FD_1 = T_1 - T_2' + \Delta{}T$$
$$FD_2 = T_3 - T_4' + \Delta{}T$$
and update its "average" of the Forward Delay of the sub-flow.
$$FD_{avg} = \frac{FD_{prev\_avg} * n + FD_2}{n + 1}$$
\end{minipage}
\end{figure}

A careful reader would notice that $FD_{avg}$ is not strictly an average in the mathematical way. Instead of giving the full weight of its past to the old value of $FD_{avg}$, we choose to give it some constant weight. In this way, the new value can influence enough in case of sudden change, but cannot completely mess up the average in case of isolated measurement error. This weight $n$ is initialized to 0 at the beginning of the sub-flow and is incremented with each received \verb!Probe! up to a given ceiling. Once this threshold is reached, it is locked and no more incremented. The historic value gains momentum up to a certain point, avoiding to overcome changes in the forward delay and to be too sensible to quick variations.

\subsection{Global reorder rate}

\todo[inline]{Je suis pas sur qu'on le fasse finalement ?}

\subsection{Loss rate}

Unlike TCP, we don't receive ack for every packet correctly transmitted. Moreover because DTLS is based on UDP, a loss is actually a normal event. To compute the loss rate, we must then add a new mechanism to support feedback. This is done by sending regularly \verb!feedback! packets from the receiver to the sender. More details about this mechanism including packet structure are presented in section \ref{sec:feedbackReport}. When we talk about sender and receiver, we divide the DTLS connection in two one-way half-connections. So if we put things back together, each host will play the role of a sender and a receiver.

In this feedback, we do not want to acknowledge every packet received. Instead we give some information about what we received in the time frame. This include : 

\begin{itemize}
\item Number of packet received
\item Minimum and maximum sequence number received
\end{itemize}

As a receiver, by transmitting these information back to the sender, we give him the ability to estimate the loss rate for this particular subflow. The minimum and maximum sequence numbers received alone are not enough to find very accurately the loss rate but this is a way to keep the packet size constant. Moreover, if we consider the reordering on a single path as a rare event, we can obtain the loss rate by 

\begin{equation*}
LR = \frac{packets_{sent}}{packets_{received}}
\end{equation*}

Where $packets_{sent}$ is maintained by the sender and $packets_{received}$ is extracted from the feedback. Note that the sender must only keep track of packets with sequence number greater than the last max sequence number received from the last feedback. By doing so, the space used to store these sequence numbers will be kept reasonably small. In the case we don't receive anymore feedback, we will progressively send less and less packets to this address until we send no more. Therefore, there is no way we exceed sender's memory simply because the receiver is dead.


\subsection{Feedback reporting}
\label{sec:feedbackReport}


Figure \ref{fig:feedback} presents an example of how feedback takes place once the communication is well established. After a reasonable number of packets is received (2 in the example), we trigger the emission of a \verb!Feedback! . Sequence numbers are put beside each message.


\begin{figure}[!h]
\centering
\begin{msc}[r]{MultiPath-DTLS Feedback}

\setlength{\instfootheight}{0em}
\setlength{\instheadheight}{0em}
\setlength{\instdist}{0.5\linewidth}
\setlength{\levelheight}{3em}

\declinst{client}{Client}{}
\declinst{server}{Server}{}

\mess{AppData 1}{client}{server}[1]
\nextlevel
\lost[r]{AppData 2}[b]{}{client}[1]
\nextlevel
\mess{AppData 3}{client}{server}[1]
\nextlevel
\mess{Feedback(2,1,3) 1}{server}[.3]{client}[1]
\nextlevel
\mess{FeedbackAck(1)}{client}{server}[1]
\nextlevel

\end{msc}
\caption{Feedback flow}
\label{fig:feedback}
\end{figure}

The structure of \verb!feedbackMessage! is presented in Listing \ref{lst:feedbackM}. In the example \verb!Feedback(2,1,3)! means that we have received 2 packets since the last acknowledged feedback. The minimum and maximum sequence number received are 1 and 3 respectively. The client replies with a \verb!feedbackAckMessage! carrying the sequence number of the corresponding \verb!feedbackMessage!.

The size of the sequence number is directly taken from the \verb!RFC6347! while we consider 8 bytes to be enough to count the packets. The threshold which triggers the transmission of a feedback must be fixed way before this limit to provide useful information even at Gigabit speed. But in case some feedback or feedbackAck are lost, we must handle more than usual values. Indeed, as long as no acknowledgement has been received, the receiver will continue to send overlapping feedback (i.e. the new feedback contains information about packets already reported in old feedback but not acknowledged).


\addtypes{struct, uint48, uint64, feedbackMessage, feedbackAckMessage}

\begin{lstlisting}[caption= Feedback message structure, label=lst:feedbackM]
struct {
  uint64    received_packets_count;
  uint48    max_sequence_number;
  uint48    min_sequence_number;
  uint64      average_forward_delay;
} feedbackMessage;
\end{lstlisting}

A \verb!feedbackMessage! is actually a modified DTLS \verb!ApplicationData! packet. In particular, it possess a signed sequence number. The latter can be used in the \verb!feedbackAckMessage! to identify uniquely this packet. In case of retransmission/loss when we receive a feedbackAck, we always know to which feedback it refers to.

\begin{lstlisting}[caption = Feedback Ack structure, label=lst:feedbackA]
struct {
  uint32    feedback_sequence_number;
} feedbackAckMessage;
\end{lstlisting}

Feedback reporting is done on a regular basis. The threshold to send a feedback is to be defined accordingly to the bandwidth of the link. On a gigabit speed link for example, we will not send feedback every 10 packets but we could on a slower link.



\appendix


\bibliographystyle{unsrt}
\bibliography{sample}

\end{document}

